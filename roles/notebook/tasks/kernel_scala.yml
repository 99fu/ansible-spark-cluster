# copy and install toree
 - debug:
    msg: "Downloading Toree:  {{ notebook.toree_pip_download_location }}{{ notebook.toree_archive_package_name }}"

 - name: download toree
   local_action: get_url url="{{ notebook.toree_pip_download_location }}{{ notebook.toree_archive_package_name }}" dest="/tmp"

 - name: copy toree to remote node
   copy:
     src: "/tmp/{{ notebook.toree_archive_package_name }}"
     dest: "{{ install_temp_dir }}/{{ notebook.toree_archive_package_name }}"
   when: (inventory_hostname in groups['master'])

 - name: pip uninstall toree
   shell: "{{ notebook.pip }} uninstall -y {{ notebook.toree_archive_package_name }}"
   ignore_errors: yes
   when: (inventory_hostname in groups['master'])

 - name: pip uninstall jupyter client
   shell: "{{ notebook.pip }} uninstall -y jupyter_client"
   ignore_errors: yes
   when: (inventory_hostname in groups['master'])

 - name: pip uninstall toree
   shell: "{{ notebook.pip }} uninstall -y {{notebook.toree_archive_package_name}}"
   ignore_errors: yes
   when: (inventory_hostname in groups['master'])

 - name: pip install toree
   shell: "{{ notebook.pip }} install --upgrade {{ install_temp_dir }}/{{notebook.toree_archive_package_name}}"
   ignore_errors: yes
   when: (inventory_hostname in groups['master'])

 - name: pip upgrade jupyter client
   shell: "{{ notebook.pip }} install --upgrade jupyter_client"
   ignore_errors: yes
   when: (inventory_hostname in groups['master'])

 - debug:
    msg: "{{ notebook.jupyter }} toree install --spark_home={{ notebook.spark_home}} --kernel_name=\"Spark 2.1\" --interpreters=Scala"

 - name: install toree kernel
   shell: >
    {{ notebook.jupyter }} toree install --spark_home={{ notebook.spark_home}} --kernel_name="Spark 2.1" --interpreters=Scala
   ignore_errors: yes
   when: (inventory_hostname in groups['master'])

 - name: retrieve kernelspec location
   shell: "/opt/anaconda2/bin/jupyter kernelspec list | grep -w spark_2.1_scala | awk '{print $2}' | xargs -i dirname {}"
   register: result
   when: (inventory_hostname in groups['master'])

 - name: store kernelspec location
   set_fact: jupyter_kernelspec_location="{{ result.stdout }}"
   with_items: "{{ result.stdout }}"
   when: (inventory_hostname in groups['master'])

 - name: remove old kernelspecs for yarn
   shell: "rm -rf {{ jupyter_kernelspec_location }}/spark_2.1_scala_yarn_cluster"
   ignore_errors: yes
   when: (inventory_hostname in groups['master'])

 - name: move kernelspec location
   shell: "mv {{ jupyter_kernelspec_location }}/spark_2.1_scala {{ jupyter_kernelspec_location }}/spark_2.1_scala_yarn_cluster"
   ignore_errors: yes
   when: (inventory_hostname in groups['master'])

 - name: update kernel launcher
   shell: "tar -zxvf {{ install_temp_dir }}/{{ notebook.elyra_kernelspec_package_name }} --strip 1 --directory {{ jupyter_kernelspec_location }}/spark_2.1_scala_yarn_cluster/ spark_2.1_scala_yarn_cluster/"
   ignore_errors: yes
   when: (inventory_hostname in groups['master'])

 - name: disable impersonation based on configuration
   shell: " sed -i 's/ --proxy-user ${KERNEL_USERNAME:-ERROR__NO__KERNEL_USERNAME}//g' {{ jupyter_kernelspec_location }}/spark_2.1_scala_yarn_cluster/kernel.json"
   ignore_errors: yes
   when: (inventory_hostname in groups['master']) and (notebook.enable_impersonation == false)

 - name: update spark home to hdp location
   shell: " sed -i 's/iop/hdp/g' {{ jupyter_kernelspec_location }}/spark_2.1_scala_yarn_cluster/kernel.json"
   ignore_errors: yes
   when: (inventory_hostname in groups['master']) and (notebook.enable_impersonation == false)
